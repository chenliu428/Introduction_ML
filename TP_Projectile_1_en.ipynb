{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b5e8a4",
   "metadata": {},
   "source": [
    "# Project - Projectile 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48830e0",
   "metadata": {},
   "source": [
    "In this project, we aim to apply supervised machine learning techniques to a classic problem in physics: predicting the horizontal distance traveled by a projectile. The objective is to build predictive models for two related but distinct tasks. \n",
    "\n",
    "- For Task 1, the goal is to predict the horizontal distance based on the initial velocity components along the x and y axes ($v_x$ and $v_y$). \n",
    "- For Task 2, the model will predict the horizontal distance using the magnitude of the initial velocity ($v$) and the launch angle ($\\alpha$). \n",
    "\n",
    "Both tasks involve training regression models on simulated projectile data, with the ultimate aim of accurately capturing the underlying physical relationships from example data. We will see that one given system when trained for different problems shows the flexibility to adapt to different situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16663d",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c811b",
   "metadata": {},
   "source": [
    "Recall key ingredients in supervised machine learning:\n",
    "\n",
    "- Task (T)\n",
    "- Experience (E)\n",
    "- Performance measure (P)\n",
    "- Hypothesis Space (Machine learning model)\n",
    "- Learning Algorithm \n",
    "- Generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8488433",
   "metadata": {},
   "source": [
    "## 2. Task-1: horizontal distance from the initial velocity components ($v_x$ & $v_y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14d18c",
   "metadata": {},
   "source": [
    "### 2.1 Define the task for Machine Learning via \"_target function_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb07686",
   "metadata": {},
   "source": [
    "In supervised machine learning, the goal is always about to infer from data (\"experience\") the relation between two sets of variables called \"**features**\" and \"**labels**\" (also called \"**targets**\") of some subject. Both **feature** and **label** can be composed by multiple quantities or variables, where each variable represents some property of the subject. \n",
    "\n",
    "> In the current project, \n",
    "> \n",
    "> - the \"subject\" under investigation is the projectile launched under the effect of gravity, \n",
    "> - the \"features\" is the pair of launching velocity components $(v_x,\\; v_y)$, and \n",
    "> - the \"label\" is the horizontal distance (i.e. along $x$) of the projectile landing position from the launching point, denoted $d$.\n",
    "\n",
    "The task meant for a supervised learning system is to return as accurately as possible the **label** when a **feature** compressing a set of pre-conventioned variables is provided. Thus from the machine's perspective, the **features** are alternatively called \"**input**\" and the **label** is alternatively called \"**output**\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdb8ec",
   "metadata": {},
   "source": [
    "Mapping from the **feature** to the **label** for a subject in the real world is the **target function**. It is the _true association of a label to some features_, i.e. the **target function**, that is meant to be learned by a machine. \n",
    "\n",
    "The **target function**, denoted $f_T(\\cdot)$, is specified by \n",
    "\n",
    "- the form of the \"feature\" (or \"input\") -- the _domain of definition_ and the meaning for each of its variables.\n",
    "- the form of the \"label\" (or \"output\") -- the _domain of definition_ and the meaning for each of its variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158dabb",
   "metadata": {},
   "source": [
    "> In the current project, the target function $f_T(\\cdot)$ is specified by \n",
    "> - the feature domain $X\\hat{=}\\{ (v_x, v_y) | v_x \\in \\mathbb{R}^+, \\; v_y \\in \\mathbb{R}^+ \\}$ where $v_x$ and $v_y$ are respectively the horizonal and vertical components of the launching velocity, and \n",
    "> - the label domain $Y\\hat{=}\\{d|d\\in \\mathbb{R}^+\\}$ where $d$ represents the landing distance of the projectile.\n",
    "> \n",
    "> The target function is formally  $$ f_T:X\\rightarrow Y \\quad \\text{or} \\quad f_T(v_x, v_y) = d$$\n",
    ">\n",
    "> In the majority of situations, unlike the current projectile problem where the target function can be resolved (using physics), the target function is too complex to be resolved, and the task of supervised machine learning is to infer that unknown **target function** using certain techniques with available data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcfd86",
   "metadata": {},
   "source": [
    "**_Specifying the target function defines the task intended by a machine learning system_**. It leads to crucial indications for \n",
    "\n",
    "1. The data pipline : the entire process from raw data collection to the formation of training and testing datasets ready for training and testing machine learning models. \n",
    "2. The hypothesis space: the scope of the candidating machine learning models to be used, that is models that can map from the feature domain $X$ to the label domain $Y$.\n",
    "3. The performance measure definition: when a target $\\hat t$ output by a machine learning system mismatches the true target $t$, one needs to specify the so called **loss function**, denoted $L(\\cdot, \\cdot)$ mapping $(t,\\hat t)\\in Y^2$ to some domain of scalar usually $\\mathbb{R}^+$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246e610",
   "metadata": {},
   "source": [
    "### 2.2 Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9e8a4",
   "metadata": {},
   "source": [
    "Once the target function is well specified, also clarified is the final product of the data pipline, i.e. an ensemble of observed \"feature-target\" pairs. In practice, if no raw data is provided, one needs to designe the data collection and cleaning up process in order to produce the ready-to-use \"feature-target\" pairs, or else one shall transform the raw data into the form of \"feature-target\" pairs required by the target function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933d508",
   "metadata": {},
   "source": [
    "In this current project, the final product of data pipline, i.e. feature-target pairs, is prepared ready in `/training_set_1.dat` for you to proceed further machine learning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc450814",
   "metadata": {},
   "source": [
    "Once the training dataset of feature-target pairs is ready, it is helful to perform the so-called \"**data exploration**\" to gain insights of the connections among all variables (in both feature and target) for a wise direction in picking up machine learning models. \n",
    "\n",
    "**Data exploration**, in principle, should be directed by generic questions about the internal mechanism underlying the subject, which varies with case and approache. Here, we will go over some common procedures for data exploration through a series of exercices and derive some insights for picking up machine learning models for the current project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce6a3a",
   "metadata": {},
   "source": [
    "#### **Exercice 2.2.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3bc3b",
   "metadata": {},
   "source": [
    "Load the followin data files with `numpy.loadtxt` function:\n",
    "  - \"training_set_1.dat\"\n",
    "  - \"test_set_1.dat\" \n",
    "\n",
    "1. Explore the loaded data structure. How many entries \"feature-target\" pairs in each dataset?\n",
    "2. Explore the header of the data files, and determine which columns are the inputs (features) and which columns are the output (targets)?\n",
    "\n",
    "Using the code cell below. Reminder: you can use `help()`, `dir()` and `type()` for the manual of new objects in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data files\n",
    "# train1 = np.loadtxt(..)\n",
    "\n",
    "# data structure, how many columns and rows?\n",
    "\n",
    "# header of the data files, which columns are the inputs and which are the output?\n",
    "\n",
    "# print the first 5 entries of the training set and the test set    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a951699",
   "metadata": {},
   "source": [
    "#### **Exercice 2.2.2** Distribution of the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb929e4",
   "metadata": {},
   "source": [
    "With the help of `matplotlib`, exploring the follwoing aspect of the input variables (feature variables) in `training_set_1.dat`:\n",
    "\n",
    "1. For each variable in the feature, what is its empirical distribution? Hint: one can plot the histogram using `matplotlib.pyplot.hist`.\n",
    "2. Is there a most probable value each input variable may take?\n",
    "3. Estimate the expectation of each input variable.\n",
    "4. Estimate the fluctuation of each input variable around its expectation.\n",
    "5. How to transform an input variable such that it has zero expectation and unity standard deviation? Such a transformation is called \"normalisation\".\n",
    "\n",
    "Use the following code cell for this exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget  # for interactive plotting\n",
    "\n",
    "# load the training set and declare input variables\n",
    "# train1 = np.loadtxt(..)\n",
    "# vx = \n",
    "# vy = \n",
    "\n",
    "# Distribution of the input variables by ploting the histogram of vx and vy\n",
    "# plt.hist(..)\n",
    "\n",
    "# Estimate the expectation\n",
    "\n",
    "# Estimate the fluctuation\n",
    "\n",
    "# Transform the input variable such that it has zero expectation and unity standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38373076",
   "metadata": {},
   "source": [
    "#### **Exercice 2.2.3** Correlation among the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef2a0",
   "metadata": {},
   "source": [
    "For the same input variables studied in the previous exercise, are these input variables correlated? Is the value of one input variable informative for the value of other input variables? Hint: one may plot one variables against another to reveal sign of mutual dependence.\n",
    "\n",
    "Use the following code cell for the investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61846063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget  # for interactive plotting\n",
    "\n",
    "# Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6d8e7",
   "metadata": {},
   "source": [
    "#### **Exercice 2.2.4** Target value distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083fa73",
   "metadata": {},
   "source": [
    "Always with the data in `training_set_1.dat`, now we turn to investigate statistical properties of the target variables. Using the same technique, explore the following aspect of the target variables\n",
    "\n",
    "1. The empirical distribution of the target variable.\n",
    "2. Is there a most probable value for the target variable?\n",
    "3. Estimate the expectation.\n",
    "4. Estimate the fluctuation.\n",
    "5. Normalise the target variables.\n",
    "\n",
    "Use the following code cell for this exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget  # for interactive plotting\n",
    "\n",
    "# Target value distribution\n",
    "\n",
    "# The most probable value for the target variable\n",
    "\n",
    "# Estimate the expectation\n",
    "\n",
    "# Estimate the fluctuation\n",
    "\n",
    "# Normalise the target variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce743c",
   "metadata": {},
   "source": [
    "#### **Exercice 2.2.5** How does the target depend on the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7af606",
   "metadata": {},
   "source": [
    "Now we turn to investigate how does the target depend on the input variables in `training_set_1.dat`.\n",
    "\n",
    "1. For each input variables, explore how does the target variable depend on the input variable using graphics. \n",
    "2. Compute the correlation coefficient between the target variable and each of the input variables.\n",
    "3. Summarize your results for Q1 and Q2.\n",
    "4. How to reveal the dependence of the target on both of the input variables? Hint: make a scattering plot where each point position represents the inputs and use its color for the target.\n",
    "5. What is your insights from Q4? What kind of form you may guess for the target function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib widget  # for interactive plotting\n",
    "\n",
    "# Scattering plot of target vs each of the input variables\n",
    "\n",
    "# Scattering plot of target vs both of the input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ac42c1",
   "metadata": {},
   "source": [
    "### 2.3 Hypothesis Space, Performance Metric, and Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5bb853",
   "metadata": {},
   "source": [
    "In one phrase, **Learning Algorithm** searches the function (also called \"hypothesis\" or \"model\") within a domain defined by the **Hypothesis Space**, that is with the optimal **performance metric** to approximates the target function. \n",
    "\n",
    "We shall go through the key concepts one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb7121",
   "metadata": {},
   "source": [
    "- A **hypothesis space**, denoted $\\mathcal{H}$, defines a set of possible functions (or models) $h(\\cdot)$ from which an \"optimal\" one can be chosen to perform the task of the target function $f_T$, i.e. mapping every feature in $X$ to a target in $Y$. For example, for some target function $f_T:\\mathbb{R}\\rightarrow \\mathbb{R}$, one may propose an hypothesis space $$\\mathcal{H}=\\{h(x)=ax^{p}| a\\in \\mathbb{R}, p\\in\\mathbb{Z}\\}\\quad .$$ \n",
    "\n",
    "  Indeed, quite often as this example, the **hypothesis space** can be viewed as a set of functions of some specific form with varying parameters, and the **hypothesis space** is equivalently represented by the space of all possible parameter settings. In the last example, $\\mathcal{H} \\leftrightarrow \\{(a,p)|(a,p)\\in \\mathbb{R}\\times\\mathbb{Z}\\} \\;(= \\mathbb{R}\\times\\mathbb{Z})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f283e",
   "metadata": {},
   "source": [
    "- The \"optimal\" function $h^*(\\cdot)$ (within in the scope of $\\mathcal{H}$) is chosen against a customery **performance metric** that quantifies how well a function $h(\\cdot)$ approximate the target function $f_T(\\cdot)$. This concept compresses two ingredients:\n",
    "  - **loss function**\n",
    "  - Loss over the population -- **Expected loss**.\n",
    "\n",
    "- **loss function**, denoted $L$, associates a degree of \"loss\", i.e. a scalar, to a pair of the true target $y = f_T(x)$ and the predicted target $\\hat{y} = h(x)$. Formally $L(\\hat{y}, y):Y^2\\rightarrow \\mathbb{R}$. The loss function basically tells how bad it is if a predicted target is $\\hat y$ while the true target is $y$. Generally speaking, you want a hypothesis resulting in a small value of the loss function. Here are two common examples of loss functions $L(\\hat y, y)=|\\hat y - y|$ and $L(\\hat y, y)=(\\hat y - y)^2$ (for the target domain $Y=\\mathbb{R}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5207b",
   "metadata": {},
   "source": [
    "#### **Exercice 2.3.1: Comparing two functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc6740",
   "metadata": {},
   "source": [
    "Assuming the target function $f_T:\\mathbb{R}\\rightarrow \\mathbb{R}$, how to compare the following two functions $h_1(x)=2x$ and $h_2(x)=2x^2$ using the same performance metric $L(\\hat y, y)=(\\hat y -y)^2$? \n",
    "\n",
    "A sample of feature-target pairs are collected from certain population-1 and stored in the file `population_1.dat`. \n",
    "\n",
    "1. How many feature-target pairs are there in this sample?\n",
    "2. Construct a numpy array of predicted targets by $h_1$ and a numpy array of predicted targets by $h_2$. Name these two arrays `y1` and `y2` respectively.\n",
    "3. Construct a scattering plot of the loss of $h_1$ as a function of the collected features. Do the same for $h_2$ on the same figure.\n",
    "4. According to the scattering plot in Q3, does $h_1$ always outperform or underperform $h_2$ ?\n",
    "5. What is the empirical distribution of the feature in this population?\n",
    "6. Take into account of the feature distribution, can you gues which function, $h_1$ or $h_2$, performs better over the entire population?\n",
    "7. Come up with a measure that quantifies the performance of a function $h$ over the entire population with respect to a loss function. Apply this measure to $h_1$ and $h_2$ with the loss $L(\\hat y, y)=(\\hat y - y)^2$. Print the result, which one is better?\n",
    "\n",
    "Use the following code cell for this exercice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.clf()\n",
    "%matplotlib widget\n",
    "\n",
    "xs = np.linspace(0, 10, 101)\n",
    "\n",
    "h1 = lambda x: 2*x\n",
    "h2 = lambda x: 2*x**2\n",
    "\n",
    "loss_func = lambda y_true, y_pred: (y_true - y_pred)**2\n",
    "\n",
    "d1 = np.loadtxt('./data/projectile_1/population_1.dat')\n",
    "\n",
    "# how many feature-target pairs are there in this sample?\n",
    "\n",
    "# construct numpy arrays of predicted targets by h1 and h2\n",
    "# y1 = \n",
    "# y2 = \n",
    "\n",
    "# scattering plot of the loss of h1 as a function of the collected features in population 1\n",
    "\n",
    "# scattering plot of the loss of h2 as a function of the collected features in population 1\n",
    "\n",
    "# histogram of the feature in this population\n",
    "\n",
    "# print the result of the performance measure for h1 and h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a487e1",
   "metadata": {},
   "source": [
    "#### **Exercice 2.3.2: Comparing again for different population**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793ec78",
   "metadata": {},
   "source": [
    "Now we investigate a different population `population_2.dat`. It is given that both pupolation 1 and population 2 admit the same target function. Compare again the performance of $h_1$ and $h_2$ but this time over population 2. \n",
    "\n",
    "1. What is distribution of feature in population 2?\n",
    "2. Compare the two populations in terms of the feature distribution.\n",
    "3. Guess over the entire population 2, which one, $h_1$ or $h_2$, will perform better?\n",
    "4. Verify your guess using the measure defined in the previous exercice Q7.\n",
    "5. What can you draw as conclusion on how to properly comparing the performance different functions? \n",
    "\n",
    "Use the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02baf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.clf()\n",
    "%matplotlib widget\n",
    "\n",
    "xs = np.linspace(0, 10, 101)\n",
    "\n",
    "h1 = lambda x: 2*x\n",
    "h2 = lambda x: 2*x**2\n",
    "\n",
    "loss_func = lambda y_true, y_pred: (y_true - y_pred)**2\n",
    "\n",
    "d2 = np.loadtxt('./data/projectile_1/population_2.dat')\n",
    "\n",
    "# what is distribution of feature in population 2?\n",
    "\n",
    "# compare the two populations in terms of the feature distribution, mean, standard deviation, etc.\n",
    "\n",
    "# verify your guess using the measure defined in the previous exercice Q7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a5389",
   "metadata": {},
   "source": [
    "- **Expected loss** and **Empirical loss** -- The loss function only assign a degree of badness to an instance of feature-target pair when a hypothesis (function) $h$ is applied. However, we want to optimise our function (within the hypothesis space) such that, it performs well over all possibly encountered features. This is why we introduce the **Expected loss** to evaluate the \"badness\" of a funtion $h$ over the entire population of features. Since one disposes only the observed data (i.e. training data) to gain some knowledge about the population, one has to use the **empirical loss** defined as $$ \\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^n L(h(x_i), y_i)$$ where $(x_1,y_1),(x_2, y_2),\\ldots,(x_n,y_n)$ are observed feature-target pairs, to estimate the **expected loss**. \n",
    "\n",
    "  **Remark**\n",
    "   - It is however important to be clear that **empiracal loss**, which estimate the performace in sample, is not **expected loss**, which measures the performance over the entire population. The only way make these two quantitiy equal, is to make $n$ goes to infinity (given that feature-target pairs are independently generated). \n",
    "   - This remark has important implications in how well a function $h$ optimised over the training samples can perform out of the sample, i.e. the expected loss. When optimisation is overly done to optimise the **empirical loss**, it can go against generalisation such that the **expected loss** is not optimal. A technique called **regularisation** is introduced for this issue, which will be discussed later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a57a15",
   "metadata": {},
   "source": [
    "- **Empirical loss** as a _landscape_. For a given set of observed data, (that is fixing the feature-target pairs), the **empirical loss** (as well as the **expected loss**) defines a multivariant function mapping hypothesis parameters to a scalar, that can be viewed as hyper-surface or a landscape.\n",
    "\n",
    "  > Taking the previous example of $\\mathcal{H}=\\{h(x)=ax^{p}| a\\in \\mathbb{R}, p\\in\\mathbb{Z}\\}$, for some given observed data $(x_1,y_1),(x_2, y_2),\\ldots,(x_n,y_n)$, the empirical loss reads explicitly $$ \\mathcal{L}(a, p) = \\frac{1}{n}\\sum_{i=1}^n L(ax_i^p, y_i) \\; .$$ Taking the value of $\\mathcal{L}(a,p)$ as the height associated to a localtion coordinate $(a,p)$, one obtains a landscape of \"mountains\" and \"valleys\" defined on the domain of $(a,p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b6680",
   "metadata": {},
   "source": [
    "- **Learning algorithm** is the specific computational scheme to search for the optimal _parameters_ from the chosen hypothesis space. For the hypothesis space in the previous example with form $h(x)=ax^p$, a learning alogrithm is series of concrete computational operations that, when it finishes, returns the \"location\" $(a,p)$ at the bottom of some \"valley\" in the landscape of **empirical loss** (that ideally also sits at the bottom of **expected loss** landscape). \n",
    "\n",
    "  The process of searching the optimal function within the hypothesis space using some learning algorithm is called **training**, and the observed feature-target pairs involved in this process is called **training set**.\n",
    "\n",
    "  When an analytical solution is not possible, an iterative loop to approach the optimal parameters must be invoked in **Learning algorithm**. In this case, a learning algoritm can viewed as a _dynamical system_ in the parameter space. \n",
    "\n",
    "  > A _dynamical system_, is a set of rules to update a state based only on the current state. Take $h(x)=ax^p$ as an example, a hypothesis (function) is completely determined by the pair $(a, p)$. A dynamical system on $(a,p)$ varies $a$ and $p$ solely based on $(a,p)$.  For example in each update step, we have the evolution $a\\rightarrow a+ \\Delta a,\\; p\\rightarrow p + \\Delta p$ where $\\Delta a = (a^2 + 3p)\\times \\ell$ and $\\Delta p = (-a+p)\\times \\ell$ with $\\ell$ setting the magnitude of each increment. Note that the increments $(\\Delta a, \\Delta p)$ are solely determined by the current state $(a,p)$. As such, some initial position $(a,p)$ draws a trajectory after multiple steps of update. In particular, when $\\ell\\rightarrow 0$, one end up with a system of differential equations.\n",
    "\n",
    "  A learning algorithm is a such a dynamical system with a set of update rules that moves the state towards lower position in the landscape of empirical loss (e.g. $\\mathcal{L}(a,p)$) and eventually stops at the bottom of some valley. **Gradient descent** is the fundamental idea underlying most of the learning algorithms dealing with **emprical loss** in supervised machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e412a",
   "metadata": {},
   "source": [
    "#### **Exercice 2.3.4 Gradient Descent in 1 dimension**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bff1d1",
   "metadata": {},
   "source": [
    "Assuming that we search the optimal function from the hypothesis space $\\mathcal{H} = \\{h(x)=kx|k\\in\\mathbb{R}\\}$. That is the optimal slope $k$ for minimizing some empirical loss. Assume also the emprical loss is given by $\\mathcal{L}(k) = k^2-5k+6$, that is a landscape define on 1 dimensional space. We search for the optimal model identified with some $k^*$. \n",
    "\n",
    "1. How to find analytically the optimal $k^*$ for this empirical loss? What is the result?\n",
    "2. What is the derivative of $L$ with respect to $k$?\n",
    "3. What is the sign of the derivative when $k$ is smaller than the optimal $k^*$? and when $k>k^*$?\n",
    "4. How does the magnitude of the derivative vary when $k$ approaches $k^*$ from the left? and from the right?\n",
    "5. Set up a rule for updating $k$ with a small magnitude of increment $\\ell$, such that where ever is $k$, the increment will be in the direction to approach $k^*$ from the current $k$.\n",
    "6. How to make the increment rule adaptive such that, the increment will \"slow down\" in each one move when $k$ is getting closer to $k^*$? Hint: derivative magnitude.\n",
    "7. Implement this learning algorithm with Python with the help of the indications in the code cell below. \n",
    "8. Plot the $k$ as a function of the iteration steps until $k$ becomes more or less stable. Make trials with different initialiation of $k$ and different values of $\\ell$. \n",
    "9. Zoom into final part of $k$ verus iteration step, what do you see for very large number of total iterations?\n",
    "9. What is the effect of $\\ell$? Hint: in terms of steps to converge, and in terms of precision to $k^*$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72346d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the empirical loss function\n",
    "def empirical_loss(k):\n",
    "    return k**2 - 5*k + 6\n",
    "\n",
    "# Define the derivative of the empirical loss\n",
    "def derivative_loss(k):\n",
    "    pass\n",
    "\n",
    "# Define the update rule\n",
    "def update_rule(k, l):\n",
    "    pass\n",
    "\n",
    "# Implement the learning algorithm\n",
    "def learning_algorithm(k, l, num_steps):\n",
    "    record_k = [k]\n",
    "    for i in range(num_steps):\n",
    "        k = update_rule(k, l)\n",
    "        record_k.append(k)\n",
    "    return np.array(record_k)\n",
    "\n",
    "# Set initial parameters\n",
    "k = 0\n",
    "\n",
    "# Set the update magnitude\n",
    "l = 0.1\n",
    "\n",
    "# Set the number of steps\n",
    "num_steps = 100\n",
    "\n",
    "# Run the learning algorithm\n",
    "\n",
    "# Plot k as a function of the iteration steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76aef6",
   "metadata": {},
   "source": [
    "#### **Exercice 2.3.3 Gradient Descent in real life**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc70233",
   "metadata": {},
   "source": [
    "You are randomly dropped from a helicopter to some where in Alpes. Your goal is to arrive at lowest point nearby.\n",
    "\n",
    "1. What did you actually do for reaching this goal? Explicitly describe your decision making process. (Ignore details such as small obsticals, plants and consider the landscape to be smooth)\n",
    "2. Consider the landscape to be smooth, and assume you can only see your seroundings, how to optimise your each step locally to follow the shortest path towards the lowest poit nearby?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0243e17",
   "metadata": {},
   "source": [
    "### 2.4 Mini linear regression with \"scikit-learn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea6906",
   "metadata": {},
   "source": [
    "Now we have clarified the machine learning task for the projectile problem and explored the training data, it is time to choose a **hypothesis space**, define a **loss function** and implement a **learning algorithm** to obtain the **trained model**, i.e. an optimal function that can make smart predictions about the distance of a projectile with the knowledge of the launching state in new experiments.\n",
    "\n",
    "For testing the performance of the trained model $h^*()$, we constructed the **test dataset** in `test_set_1.dat` and use the empirical loss of $h^*()$ applied on this test dataset as a survey for the true performance, i.e. the expected loss. For this survey to be faithful, it is crucial to guarantee **test set** and **training set** do not share any data points (feature-target pairs), otherwise the real performance could be overestimated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6565d",
   "metadata": {},
   "source": [
    "To have a taste of how machine learning works, we are going to use the library \"scikit-learn\" (`import sklearn`) to realise machine learning of simple \"ordinary least square regression\", which means \n",
    "\n",
    "- For the **hypothesis space**, we choose a simple linear model that is $$\\mathcal{H}=\\{ h(v_x, v_y) = w_x v_x + w_y v_y + w_0| (w_x, w_y, w_0) \\in \\mathbb{R}^3\\}\\;.$$ Hence the training wind up to optimising the parameter triplet $(w_x, w_y, w_0)$ with respect to the empirical loss. The coefficients $(w_0, w_x, w_y)$ are called \"weights\" in a linear model.\n",
    "- For the **emprical loss**, we choos the **loss function** to be $$L(\\hat d, d ) = (\\hat d - d)^2$$ where $\\hat d$ and $d$ are the predicted and real distances respectively.\n",
    "- The optimal hypothesis for the above setting can be analysically solved by matrix inversion, that is the **learning algorithm** is realised via numerical matrix inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe5b76",
   "metadata": {},
   "source": [
    "#### **Exercice 2.4.1**\n",
    "\n",
    "1. Take into account of the results in data exploration about the dependence of $d$ on $(v_x, v_y)$, what can you guess about the signs of $w_x$ and $w_y$ of an optimal linear function?\n",
    "\n",
    "2. Write the expression for the empirical loss, if $n$ feature-target pairs are given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388304f",
   "metadata": {},
   "source": [
    "#### Simple Ordinary Least Square (OLS) Regression with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c20a8",
   "metadata": {},
   "source": [
    "We use the data in `training_set_1.dat` for training and `test_set_1.dat` for evaluating the trained model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91febf65",
   "metadata": {},
   "source": [
    "The following code cell realises the entire process of OLS regression. Read, run and play with the code, for answering questions in the following up exercices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e916bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train1 = np.loadtxt('./data/projectile_1/training_set_1.dat')\n",
    "test1 = np.loadtxt('./data/projectile_1/test_set_1.dat')\n",
    "\n",
    "# Use training data (vx, vy) to predict d\n",
    "X_train = train1[:, :2]\n",
    "y_train = train1[:, 2]\n",
    "X_test = test1[:, :2]\n",
    "y_test = test1[:, 2]\n",
    "\n",
    "# Initialize OLS regression model\n",
    "ols = LinearRegression()\n",
    "\n",
    "# print weights before training\n",
    "print(\"Before training ------------\")\n",
    "try:\n",
    "    print(\"Coefficients before training:\", ols.coef_)\n",
    "    print(\"Intercept before training:\", ols.intercept_)\n",
    "except:\n",
    "    print(\"Weights before training: not available\")\n",
    "\n",
    "# Train OLS regression model\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "# print weights after training\n",
    "print(\"After training ------------\")\n",
    "try:\n",
    "    print(\"Coefficients after training:\", ols.coef_)\n",
    "    print(\"Intercept after training:\", ols.intercept_)\n",
    "except:\n",
    "    print(\"Weights after training: not available\")\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = ols.predict(X_test)\n",
    "\n",
    "# Compute performance measure (mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (on test set):\", mse)\n",
    "\n",
    "%matplotlib widget\n",
    "plt.clf()\n",
    "plt.scatter(y_test, y_pred, s=20, c='b', marker='o', alpha=0.5)\n",
    "plt.plot([100, 3000], [100, 3000], 'k--')\n",
    "plt.show()\n",
    "\n",
    "# Implement the empirical loss\n",
    "def empirical_loss(X, y, model):\n",
    "    pass\n",
    "\n",
    "    # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc36a77",
   "metadata": {},
   "source": [
    "#### Exercice 2.4.2 OLS regression with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74c5f6",
   "metadata": {},
   "source": [
    "1. What is the reference name (or object) that carries the information about the linear model space, the empirical loss and the training method? How is the this object created by code?\n",
    "2. After the training and testing datasets are loaded and prepared, what are the two crucial calls / steps to obtain a trained simple linear model?\n",
    "3. Which line of code carries the actual training process? \n",
    "4. How are training data fed to the training process? Importantly, what do the rows and columns represents in `X_train` and `y_train`? What if we have $M$ feature-target pairs where each feature compresses $st input variables, and each target compresses $t$ variables?\n",
    "5. After training, which values do the weights take for $w_x, w_y, w_0$ respectively?\n",
    "6. What the plot should look like if the trained model makes perfect predictions?\n",
    "7. Complete the function `empirical_loss` taking `X`, `y` feature-target pairs in the same format as `y_test`, `y_pred` and a model object `model` as its arguments to return the empirical loss, without using `mean_squared_loss`. Verify it returns the same result as `mse`.\n",
    "8. Use the `empirial_loss` to evaluate the trained model on the training set. How does it compare to the empirical loss on the test set? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c693dc",
   "metadata": {},
   "source": [
    "#### Exercice 2.4.3 Create your own linear model with `class`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f39f5d",
   "metadata": {},
   "source": [
    "Class is a core concept in Python, since in Python everything is an object of certain \"type\". This \"type\" refers to some \"class\". For example, run the following code cell, and you will see that all buit-in data types are certain classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(0)\n",
    "print(type(a))\n",
    "\n",
    "b = float(0.0)\n",
    "print(type(b))\n",
    "\n",
    "c = str('0')\n",
    "print(type(c))\n",
    "\n",
    "d = list([0])\n",
    "print(type(d))\n",
    "\n",
    "e = list()\n",
    "print(type(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43737083",
   "metadata": {},
   "source": [
    "In the above code cell each variable name (also called \"reference\") represent an object or an instance of certain class. For example, `a` is an instance or object of `int` class, `d` and `e` are two different objects or instances of the same class `list`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdf9eb",
   "metadata": {},
   "source": [
    "A class is a blueprint or meta-form for creating concrete objects. Here is a piece of code to declare a `my_linear_model` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_linear_model:\n",
    "    def __init__(self, w_x=0.0, w_y=0.0, w_0=0.0):\n",
    "        self.w_x = w_x\n",
    "        self.w_y = w_y\n",
    "        self.w_0 = w_0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert X.ndim == 2 and X.shape[1] == 2, \"X must be a 2D array with 2 columns\"\n",
    "        return self.w_x*X[:, 0] + self.w_y*X[:, 1] + self.w_0\n",
    "\n",
    "my_model1 = my_linear_model()\n",
    "my_model2 = my_linear_model(1.0, 1.0, 1.0)\n",
    "\n",
    "X = np.array([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])\n",
    "\n",
    "y_pred1 = my_model1.predict(X)\n",
    "y_pred2 = my_model2.predict(X)\n",
    "\n",
    "print('my_model1.predict(X)', y_pred1)\n",
    "print('my_model2.predict(X)', y_pred2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba586d6c",
   "metadata": {},
   "source": [
    "1. Craete an instance `my_traine_model` of class `my_linear_model` with the weights initialised using the trained model weights.\n",
    "2. Make a prediction using this instance with `X_test`, and compare with the prediction of trained model `ols`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0dffdb",
   "metadata": {},
   "source": [
    "### 2.5 Linear models and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c7b558",
   "metadata": {},
   "source": [
    "#### 2.5.1 Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93581692",
   "metadata": {},
   "source": [
    "A **linear model** is one of the simplest and most fundamental types of machine learning models.\n",
    "It assumes that the **target variable** ( $y$ ) can be expressed as a **linear combination** of the **input variables** ( $x_1, x_2, \\ldots, x_n$ ):\n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n \n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $w_0$ is the **bias (intercept)** term,\n",
    "* $w_1, \\ldots, w_n$  are the **model coefficients (weights)**,\n",
    "\n",
    "In vector form:\n",
    "\n",
    "$$\n",
    "y = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "This formulation applies to both **regression** (predicting scalar outcomes) and **classification** (predicting categories, often via logistic or softmax functions).\n",
    "\n",
    "\n",
    "> **Why Linear Models Matter**\n",
    ">\n",
    "> Linear models are conceptually simple but extremely powerful:\n",
    "> \n",
    "> * They are **easy to interpret** — each weight directly shows how much a feature influences the output.\n",
    "> * They are **computationally efficient** — training involves solving convex optimization problems (often via least squares or gradient descent).\n",
    "> * They serve as a **baseline model** — often the first model tested before more complex nonlinear ones.\n",
    "> * Many nonlinear models (like neural networks) can be viewed as compositions of **linear transformations plus nonlinearities**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86eb163",
   "metadata": {},
   "source": [
    "#### 2.5.2 Feature Engineering and the Power of Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b6aab",
   "metadata": {},
   "source": [
    "Because linear models only learn *linear relationships*, the expressiveness of the model depends heavily on the **features** provided. That’s where **feature engineering** becomes critical.\n",
    "\n",
    "**Feature engineering** means transforming raw feature input variables into informative features that better capture the underlying relationships between inputs and outputs. For linear models, this can include:\n",
    "\n",
    "* **Polynomial features:** ( $x, x^2, x^3, \\ldots$ ) allow modeling nonlinear trends.\n",
    "* **Interaction terms:** ( $x_1 \\times x_2$ ) capture nonlinearity between features.\n",
    "* **Normalization/scaling:** ensures all features contribute proportionally (important for gradient-based optimization).\n",
    "* **Feature selection:** removing redundant or irrelevant variables improves generalization.\n",
    "\n",
    "With the right feature transformations, a linear model can approximate surprisingly complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff713b",
   "metadata": {},
   "source": [
    "Formally for a feature of $n$ input variables $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$ (or also commonly called \"$n$ features for one input\"), **feature engineering** consists in constructing $m$ complex features $\\phi_1(\\mathbf{x}), \\phi_2(\\mathbf{x}), \\ldots, \\phi_m(\\mathbf{x})$ from the $n$ raw features, with usually $m>n$, for capturing non-linearity in the target function. Each $\\phi_i(\\mathbf{x})$ is a function of all raw input variables $x_1, x_2, \\ldots, x_n$. \n",
    "\n",
    "A more expressive linear model now pocesses $m$ weights and reads \n",
    "\n",
    "$$\n",
    "y = w_1 \\phi_1(\\mathbf x) + w_2 \\phi_2(\\mathbf x) + \\cdots + w_m \\phi_m(\\mathbf x) + w_0\n",
    "$$\n",
    "\n",
    "or in a vector form\n",
    "\n",
    "$$\n",
    "y = \\mathbf{w}^T\\cdot \\mathbf{\\phi}(\\mathbf{x}) + w_0\\;.\n",
    "$$\n",
    "\n",
    "As such the linear regression is transformed into a new one but always **linear** in the tuning parameters $\\mathbf{w}$.\n",
    "\n",
    "For example, **polynomial features** for a feature of single variable $x$, $\\phi_p(x) = x^p$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce17c57",
   "metadata": {},
   "source": [
    "#### **Exercice 2.5.1 More data exploration for the projectile**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bb268",
   "metadata": {},
   "source": [
    "We are going to dive deeper in data exploration with the `training_set_1.dat`. Using a code cell below to investigate the following questions.\n",
    "\n",
    "1. Is the dependence of the distance $d$ linear on each of $v_x$ and $v_y$, when the other is fixed?\n",
    "2. How does the dependence of $d$ on $v_x$ for a fixed $v_y$ varies when varying $v_y$? \n",
    "3. The same question as Q2 except exchanging $v_x$ and $v_y$.\n",
    "4. What kind of form can you guess for the target function?\n",
    "5. Is your guess consistent with the results (especially the colored scattering plot) in the previous data exploration?\n",
    "6. Is your guess consistent with the point cloud shape in the OLS regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084590f",
   "metadata": {},
   "source": [
    "#### **Exercice 2.5.2 OLS regression with Feature engineering for projectile**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc6f96",
   "metadata": {},
   "source": [
    "Based on the previous OLS results and the analysis above, a simple linear form $h(v_x, v_y) = w_x v_x + w_y v_y + w_0$ does not capture the complexity of the target function. We are going to transform the raw featuers $v_x,\\; v_y$ to higher order features. Each new feature $\\phi_{p,q}$ is of form $\\phi_{p,q} = v_x^pv_y^q$, with $p+q$ from $0$ up to $3$.\n",
    "\n",
    "1. For $p+q=0, 1, 2, 3$, list all possible features $phi$. In such way, we transform 2 input variables into a feature of $m$ variables, what is $m$?\n",
    "2. Using a code cell to load prepare `X_train`, `y_train`, `X_test`, `y_test` as the OLS regression, and then construct, using the same format of `X_train` or `X_test`, `Xnew_train` and `Xnew_test` of the new features. Keep a track of which column in the input matrix corresponding to which $(p,q)$ pair.\n",
    "3. Redo the linear regression, this time with an linear model object `ols_new`, with the new features.\n",
    "4. Make a scattering plot of $y_pred_new$ versus $y_test$, in the same figure to compare with OLS.\n",
    "5. Evaluate the empirical loss of the newly predicted target on the test dataset. How does it compare with OLS? Is it consistent with the could points shape changes?\n",
    "6. Investigate the coefficients for each new feature index by $(p,q)$. Which one is more special than others? What is its value and why (from a physics point of view)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "train1 = np.loadtxt('./data/projectile_1/training_set_1.dat')\n",
    "test1 = np.loadtxt('./data/projectile_1/test_set_1.dat')\n",
    "\n",
    "# Use training data (vx, vy) to predict dx\n",
    "X_train = train1[:, :2]\n",
    "y_train = train1[:, 2]\n",
    "X_test = test1[:, :2]\n",
    "y_test = test1[:, 2]\n",
    "\n",
    "# Construct the new features\n",
    "\n",
    "\n",
    "# Initialize OLS regression model\n",
    "ols = LinearRegression()\n",
    "ols_new = LinearRegression()\n",
    "\n",
    "# Train OLS regression model with both the raw features and the new features\n",
    "\n",
    "# Predict on test set\n",
    "# y_pred = \n",
    "# y_pred_new = \n",
    "\n",
    "# Compute performance measure (mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_new = mean_squared_error(y_test, y_pred_new)\n",
    "\n",
    "print(\"Mean Squared Error     (on test set):\", mse)\n",
    "print(\"Mean Squared Error new (on test set):\", mse_new)\n",
    "\n",
    "# Investigate the model coefficients for the new features\n",
    "\n",
    "# Scattering plot of y_pred_new versus y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7dc6f",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "- Check feature scales and spreads\n",
    "- Problem with that\n",
    "- Normalisztion\n",
    "- Exercice to implement\n",
    "- Redo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1c54d",
   "metadata": {},
   "source": [
    "### Regularisation\n",
    "\n",
    "- The problem of overfitting, hightlight previous results, loss in the train vs loss in the test\n",
    "- Idea to introduce penalty\n",
    "- Realize with sklearn Ridge\n",
    "- Redo with 3 value of alpha and compare the results -- > how to choose alphe\n",
    "- Cross validation to choose alpha\n",
    "- redo with a series of alpha and plot the validation loss versus alpha --> minimal optimal alpha\n",
    "- on test, and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Use training data (vx, vy) to predict dx, same as above\n",
    "X_train = train1[:, :2]\n",
    "y_train = train1[:, 2]\n",
    "X_test = test1[:, :2]\n",
    "y_test = test1[:, 2]\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Train Ridge regression model with penalty coefficient alpha=1.0\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Compute performance measure (mean squared error)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"Ridge Regression Mean Squared Error (on test set):\", mse_ridge)\n",
    "\n",
    "# Optionally, show model coefficients\n",
    "print(\"Ridge Regression learned coefficients:\", ridge.coef_)\n",
    "print(\"Ridge Regression learned intercept:\", ridge.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec3050",
   "metadata": {},
   "source": [
    "## Proper sklearn project with *_set_2.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd6960",
   "metadata": {},
   "source": [
    "### General gradient descent\n",
    "\n",
    "- Gradient descent\n",
    "- Stationary point and matrix inversion for analytical solution for quaradic\n",
    "- Effect of learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583d24a",
   "metadata": {},
   "source": [
    "### Bias-Variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306d8ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for generating training and test sets ./data/projectile_1\n",
    "g = 9.81\n",
    "\n",
    "def distance_vx_vy(vx, vy):\n",
    "    return vx*(vy/g)*2\n",
    "    \n",
    "def distance_v_alpha(v, alpha):\n",
    "    return v*np.sin(2*alpha)*(v/g)\n",
    "\n",
    "n_train = 10000\n",
    "n_test = 2000\n",
    "\n",
    "vx = np.random.normal(80, 15, n_train + n_test)    \n",
    "vy = np.random.normal(80, 15, n_train + n_test)\n",
    "\n",
    "v = np.sqrt(vx**2 + vy**2)\n",
    "alpha = np.arctan2(vy, vx)\n",
    "\n",
    "dx_std = 10\n",
    "dx = vx*(vy/g)*2 + np.random.normal(0, dx_std, n_train + n_test)\n",
    "\n",
    "\n",
    "train1 = np.zeros((n_train, 3))\n",
    "train1[:,0] = vx[:n_train]\n",
    "train1[:,1] = vy[:n_train]\n",
    "train1[:,2] = dx[:n_train]\n",
    "\n",
    "test1 = np.zeros((n_test, 3))\n",
    "test1[:,0] = vx[n_train:n_train+n_test]\n",
    "test1[:,1] = vy[n_train:n_train+n_test]\n",
    "test1[:,2] = dx[n_train:n_train+n_test]\n",
    "\n",
    "train2 = np.zeros((n_train, 3))\n",
    "train2[:,0] = v[:n_train]\n",
    "train2[:,1] = alpha[:n_train]\n",
    "train2[:,2] = dx[:n_train]\n",
    "\n",
    "test2 = np.zeros((n_test, 3))\n",
    "test2[:,0] = v[n_train:n_train+n_test]\n",
    "test2[:,1] = alpha[n_train:n_train+n_test]\n",
    "test2[:,2] = dx[n_train:n_train+n_test]\n",
    "\n",
    "\n",
    "# np.savetxt('./data/projectile_1/training_set_1.dat', train1, header='vx vy dx')\n",
    "# np.savetxt('./data/projectile_1/training_set_2.dat', train2, header='v alpha dx')\n",
    "# np.savetxt('./data/projectile_1/test_set_1.dat', test1, header='vx vy dx')\n",
    "# np.savetxt('./data/projectile_1/test_set_2.dat', test2, header='v alpha dx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71a504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca053fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc = plt.scatter(vx[:1000], vy[:1000], c=dx[:1000], marker='o')\n",
    "plt.colorbar(sc, label='dx')\n",
    "plt.xlabel('vx')\n",
    "plt.ylabel('vy')\n",
    "plt.title('vy vs vx colored by dx (first 1000 points)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b39c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vx, dx, 'o', alpha=0.2, mec='none' )\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('vx')\n",
    "plt.ylabel('dx')\n",
    "plt.title('dx vs vx')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80305028",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2, 101)\n",
    "y1 = 2*x\n",
    "y2 = 2*x**2\n",
    "z = 2*x**1.5\n",
    "\n",
    "plt.plot(x, (y1-z)**2, label='y1')\n",
    "plt.plot(x, (y2-z)**2, label='y2')\n",
    "plt.legend()\n",
    "\n",
    "s1 = np.random.exponential(0.1,1000)\n",
    "t1 = 2*s1**1.5 \n",
    "s2 = np.random.exponential(1.0,1000)\n",
    "t2 = 2*s2**1.5\n",
    "\n",
    "plt.plot(s1, t1, 'o', alpha=0.2, mec='none')\n",
    "plt.plot(s2, t2, 'o', alpha=0.2, mec='none')\n",
    "plt.show()\n",
    "\n",
    "s = s1\n",
    "t = t1\n",
    "h1 = 2*s\n",
    "h2 = 2*s**2\n",
    "plt.figure()\n",
    "plt.plot(t, h1, 'o', alpha=0.2, mec='none')\n",
    "plt.plot(t, h2, 'o', alpha=0.2, mec='none')\n",
    "plt.show()\n",
    "\n",
    "print('h1', np.mean(np.abs(h1-t)))\n",
    "print('h2', np.mean(np.abs(h2-t)))\n",
    "\n",
    "d1 = np.zeros((len(s1), 2))\n",
    "d2 = np.zeros((len(s2), 2))\n",
    "d1[:,0] = s1\n",
    "d1[:,1] = t1\n",
    "d2[:,0] = s2\n",
    "d2[:,1] = t2\n",
    "np.savetxt('./data/projectile_1/population_1.dat', d1, header='x y')\n",
    "np.savetxt('./data/projectile_1/population_2.dat', d2, header='x y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d201a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

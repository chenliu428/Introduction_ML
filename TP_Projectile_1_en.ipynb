{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b5e8a4",
   "metadata": {},
   "source": [
    "# Project - Projectile 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48830e0",
   "metadata": {},
   "source": [
    "In this project, we aim to apply supervised machine learning techniques to a classic problem in physics: predicting the horizontal distance traveled by a projectile. The objective is to build predictive models for two related but distinct tasks. \n",
    "\n",
    "- For Task 1, the goal is to predict the horizontal distance based on the initial velocity components along the x and y axes ($v_x$ and $v_y$). \n",
    "- For Task 2, the model will predict the horizontal distance using the magnitude of the initial velocity ($v$) and the launch angle ($\\alpha$). \n",
    "\n",
    "Both tasks involve training regression models on simulated projectile data, with the ultimate aim of accurately capturing the underlying physical relationships from example data. We will see that one given system when trained for different problems shows the flexibility to adapt to different situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16663d",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c811b",
   "metadata": {},
   "source": [
    "Recall key ingredients in supervised machine learning:\n",
    "\n",
    "- Task (T)\n",
    "- Experience (E)\n",
    "- Performance measure (P)\n",
    "- Hypothesis Space (Machine learning model)\n",
    "- Learning Algorithm \n",
    "- Generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8488433",
   "metadata": {},
   "source": [
    "## 2. Task-1: horizontal distance from the initial velocity components ($v_x$ & $v_y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14d18c",
   "metadata": {},
   "source": [
    "### 2.1 Formulate the task for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb07686",
   "metadata": {},
   "source": [
    "In supervised machine learning, the goal is always about to infer from data (\"experience\") the relation between two sets of variables called \"**features**\" and \"**labels**\" (also called \"**targets**\") of some subject. Both **feature** and **label** can be composed by multiple quantities or variables, where each variable represents some property of the subject. The task meant for a supervised learning system is to return as accurately as possible the **label** when a **feature** compressing a set of pre-conventioned variables is provided. Thus from the machine's perspective, the **features** are alternatively called \"**input**\" and the **label** is alternatively called \"**output**\". \n",
    "\n",
    "\n",
    "In the current project, \n",
    "\n",
    "- the \"subject\" under investigation is the projectile launched under the effect of gravity, \n",
    "- the \"features\" is the pair of launching velocity components $(v_x,\\; v_y)$, and \n",
    "- the \"label\" is the horizontal distance (i.e. along $x$) of the projectile landing position from the launching point, denoted $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdb8ec",
   "metadata": {},
   "source": [
    "Mapping from the **feature** to the **label** for a subject in the real world is the **target function**. It is the _true association of a label to some features_, i.e. the **target function**, that is meant to be learned by a machine. \n",
    "\n",
    "> A **target function** is the real / true function that associates a specific value of **label** for a given **feature**.\n",
    "> In the current project, the target function is the function $f_T(\\cdot)$ that takes a set of features $(v_x, v_y)$ and return the distance $d$ in a real world projectile experiment. Formally, $$ f_T(\\cdot):\\{(v_x, v_y)\\}\\rightarrow \\{ d \\} \\quad \\text{equivalently}\\quad f_T(v_x, v_y) = d\\quad.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ecc3d",
   "metadata": {},
   "source": [
    "The **target function**, denoted $f_T(\\cdot)$, is specified by \n",
    "\n",
    "- the form of the \"feature\" (or \"input\") -- the _domain of definition_ and the meaning for each of its variables.\n",
    "- the form of the \"label\" (or \"output\") -- the _domain of definition_ and the meaning for each of its variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158dabb",
   "metadata": {},
   "source": [
    "> In the current project, the target function $f_T(\\cdot)$ is specified by \n",
    "> - the feature domain $D_F\\hat{=}\\{ (v_x, v_y) | v_x \\in \\mathbb{R}^+, \\; v_y \\in \\mathbb{R}^+ \\}$ where $v_x$ and $v_y$ are respectively the horizonal and vertical components of the launching velocity, and \n",
    "> - the label domain $D_T\\hat{=}\\{d|d\\in \\mathbb{R}^+\\}$ where $d$ represents the landing distance of the projectile.\n",
    "> \n",
    "> The target function is formally  $$ f_T:D_F\\rightarrow D_T $$\n",
    ">\n",
    "> In the majority of situations, unlike the current projectile problem where the target function can be resolved (using physics), the target function is too complex to be resolved, and the task of supervised machine learning is to infer that unknown **target function** using certain techniques with available data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246e610",
   "metadata": {},
   "source": [
    "### 2.2 Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7af606",
   "metadata": {},
   "source": [
    "- Load data files:\n",
    "  - \"training_set_1.dat\"\n",
    "  - \"test_set_1.dat\" \n",
    "  - \"training_set_2.dat\"\n",
    "  - \"test_set_2.dat\"\n",
    "with `numpy.loadtxt`. \n",
    "\n",
    "- Explore the header of the data file, and determine which columns are the inputs and which columns are the output.\n",
    "\n",
    "- Explore the loaded data structure. How many entries (samples) in each dataset?\n",
    "\n",
    "- Using plotting tools `matplotlib` to explore the following aspects of the datasets\n",
    "\n",
    "  - For each quantity, what is its distribution in the sample? Is the distribution in the training set aligned with the test set? \n",
    "\n",
    "  - How are different quantites correlated with each other? \n",
    "\n",
    "  - How does the target value depend on the input features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0243e17",
   "metadata": {},
   "source": [
    "### 2.3 Mini linear regression with \"scikit-learn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388304f",
   "metadata": {},
   "source": [
    "#### Ordinary Least Square Regression (without feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use training data (vx, vy) to predict dx\n",
    "X_train = train1[:, :2]\n",
    "y_train = train1[:, 2]\n",
    "X_test = test1[:, :2]\n",
    "y_test = test1[:, 2]\n",
    "\n",
    "# Initialize OLS regression model\n",
    "ols = LinearRegression()\n",
    "\n",
    "# Train OLS regression model\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = ols.predict(X_test)\n",
    "\n",
    "# Compute performance measure (mean squared error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (on test set):\", mse)\n",
    "\n",
    "# Optionally, show model coefficients\n",
    "print(\"Learned coefficients:\", ols.coef_)\n",
    "print(\"Learned intercept:\", ols.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7dc6f",
   "metadata": {},
   "source": [
    "#### Ordinary Least Square Regression with feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9265744",
   "metadata": {},
   "source": [
    "For a more complex model, one needs to construct more tailored features from the raw input features â€” a process known as _feature engineering_.\n",
    "\n",
    "We will explore a specific type of feature engineering -- polynomial feature expansion by _taking powers and cross-products of the original features, allowing models to capture nonlinear relationships within the data_.\n",
    "\n",
    "We will perform the polynomial expansion up to order 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675af983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature maxtrix in analogy with X_train before, but this time with polynomial features up to order 3 constructed from the raw input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the traininig and testing process as before, and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Use training data (vx, vy) to predict dx, same as above\n",
    "X_train = train1[:, :2]\n",
    "y_train = train1[:, 2]\n",
    "X_test = test1[:, :2]\n",
    "y_test = test1[:, 2]\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Train Ridge regression model with penalty coefficient alpha=1.0\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Compute performance measure (mean squared error)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"Ridge Regression Mean Squared Error (on test set):\", mse_ridge)\n",
    "\n",
    "# Optionally, show model coefficients\n",
    "print(\"Ridge Regression learned coefficients:\", ridge.coef_)\n",
    "print(\"Ridge Regression learned intercept:\", ridge.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306d8ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code for generating training and test sets ./data/projectile_1\n",
    "g = 9.81\n",
    "\n",
    "def distance_vx_vy(vx, vy):\n",
    "    return vx*(vy/g)*2\n",
    "    \n",
    "def distance_v_alpha(v, alpha):\n",
    "    return v*np.sin(2*alpha)*(v/g)\n",
    "\n",
    "n_train = 10000\n",
    "n_test = 2000\n",
    "\n",
    "vx = np.random.normal(80, 15, n_train + n_test)    \n",
    "vy = np.random.normal(80, 15, n_train + n_test)\n",
    "\n",
    "v = np.sqrt(vx**2 + vy**2)\n",
    "alpha = np.arctan2(vy, vx)\n",
    "\n",
    "dx_std = 10\n",
    "dx = vx*(vy/g)*2 + np.random.normal(0, dx_std, n_train + n_test)\n",
    "\n",
    "\n",
    "train1 = np.zeros((n_train, 3))\n",
    "train1[:,0] = vx[:n_train]\n",
    "train1[:,1] = vy[:n_train]\n",
    "train1[:,2] = dx[:n_train]\n",
    "\n",
    "test1 = np.zeros((n_test, 3))\n",
    "test1[:,0] = vx[n_train:n_train+n_test]\n",
    "test1[:,1] = vy[n_train:n_train+n_test]\n",
    "test1[:,2] = dx[n_train:n_train+n_test]\n",
    "\n",
    "train2 = np.zeros((n_train, 3))\n",
    "train2[:,0] = v[:n_train]\n",
    "train2[:,1] = alpha[:n_train]\n",
    "train2[:,2] = dx[:n_train]\n",
    "\n",
    "test2 = np.zeros((n_test, 3))\n",
    "test2[:,0] = v[n_train:n_train+n_test]\n",
    "test2[:,1] = alpha[n_train:n_train+n_test]\n",
    "test2[:,2] = dx[n_train:n_train+n_test]\n",
    "\n",
    "\n",
    "# np.savetxt('./data/projectile_1/training_set_1.dat', train1, header='vx vy dx')\n",
    "# np.savetxt('./data/projectile_1/training_set_2.dat', train2, header='v alpha dx')\n",
    "# np.savetxt('./data/projectile_1/test_set_1.dat', test1, header='vx vy dx')\n",
    "# np.savetxt('./data/projectile_1/test_set_2.dat', test2, header='v alpha dx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71a504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca053fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc = plt.scatter(vx[:1000], vy[:1000], c=dx[:1000], marker='o')\n",
    "plt.colorbar(sc, label='dx')\n",
    "plt.xlabel('vx')\n",
    "plt.ylabel('vy')\n",
    "plt.title('vy vs vx colored by dx (first 1000 points)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b39c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vx, dx, 'o', alpha=0.2, mec='none' )\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('vx')\n",
    "plt.ylabel('dx')\n",
    "plt.title('dx vs vx')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80305028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
